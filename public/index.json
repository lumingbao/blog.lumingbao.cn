[{"categories":["日常记录"],"content":"zoc license code ","date":"2024-01-15","objectID":"/archives/zblbvrl6/:0:0","tags":["技巧"],"title":"zoc license code","uri":"/archives/zblbvrl6/"},{"categories":["日常记录"],"content":"一：点击导航栏上的zoc-about zoc，然后： ","date":"2024-01-15","objectID":"/archives/zblbvrl6/:1:0","tags":["技巧"],"title":"zoc license code","uri":"/archives/zblbvrl6/"},{"categories":["日常记录"],"content":"二：点击enter license: # 注册码 Part A: 51698/01027/34713 Part B: 00937 Part A: 50866/01027/47775 Part B: 57341 Part A: 53866/01028/18861 Part B: 45757 Part A: 03754/01029/23239 Part B: 50179 Part A: 55834/01027/59600 Part B: 43010 Part A: 11370/01027/29134 Part B: 51686 Part A: 61298/01028/48550 Part B: 00985 ","date":"2024-01-15","objectID":"/archives/zblbvrl6/:2:0","tags":["技巧"],"title":"zoc license code","uri":"/archives/zblbvrl6/"},{"categories":["日常记录"],"content":"Mac环境下安装Node.js多版本管理工具NVM ","date":"2023-09-28","objectID":"/archives/nmcs5jwv/:0:0","tags":["技巧"],"title":"Mac环境下安装Node.js多版本管理工具NVM","uri":"/archives/nmcs5jwv/"},{"categories":["日常记录"],"content":"一：安装 日常开发过程中，手动进行Node.js的多版本管理非常不便。这里推荐使用nvm。对于Mac环境，不推荐使用brew进行安装。可先通过下述链接获取nvm安装脚本并执行脚本来实现 # nvm安装脚本 https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh # 执行脚本 sh ./install.sh 这里的终端环境为zsh，故在～/.zshrc文件当中添加如下配置，并重新加载配置文件 # 在.zshrc文件中添加如下配置 export NVM_DIR=\"$HOME/.nvm\" [ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\" # This loads nvm [ -s \"$NVM_DIR/bash_completion\" ] \u0026\u0026 \\. \"$NVM_DIR/bash_completion\" # This loads nvm bash_completion # 重新加载配置文件 source ~/.zshrc 一切完毕后，可通过查看nvm版本确认是否安装成功 # 查看nvm版本 nvm -v 同时由于众所周知的原因，这里将NVM源切换为国内的镜像源。这里我们使用淘宝的镜像源。故在～/.zshrc文件当中添加相应的环境变量 # 添加环境变量, 值为国内的淘宝镜像源 export NVM_NODEJS_ORG_MIRROR=http://npmmirror.com/mirrors/node export NVM_IOJS_ORG_MIRROR=http://npmmirror.com/mirrors/iojs # 重新加载配置文件 source ~/.zshrc ","date":"2023-09-28","objectID":"/archives/nmcs5jwv/:1:0","tags":["技巧"],"title":"Mac环境下安装Node.js多版本管理工具NVM","uri":"/archives/nmcs5jwv/"},{"categories":["日常记录"],"content":"二：常用命令 # 查看可安装版本 nvm ls-remote # 查看已安装版本 nvm ls # 安装指定版本 nvm install \u003cNode.js的版本号\u003e # 卸载指定版本 nvm uninstall \u003cNode.js的版本号\u003e # 查看当前版本 nvm current # 切换至指定版本 nvm use \u003cNode.js的版本号\u003e nvm use \u003c别名\u003e # 设置默认版本 nvm alias default \u003cNode.js的版本号\u003e # 对指定版本添加别名 nvm alias \u003c别名\u003e \u003cNode.js的版本号\u003e # 删除已定义别名 nvm unalias \u003c别名\u003e ","date":"2023-09-28","objectID":"/archives/nmcs5jwv/:2:0","tags":["技巧"],"title":"Mac环境下安装Node.js多版本管理工具NVM","uri":"/archives/nmcs5jwv/"},{"categories":["日常记录"],"content":"Docker部署OpenVPN ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:0","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"拉取镜像、创建目录 docker pull kylemanna/openvpn:2.4 mkdir -p /data/openvpn ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:1","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"1、使用openvpn生成配置文件，注意目录映射和IP地址换成自己的 docker run \\ -v /data/openvpn:/etc/openvpn \\ --rm kylemanna/openvpn:2.4 ovpn_genconfig \\ -u udp://127.0.0.1 执行完命令后可在目录/data/openvpn中看到相应的配置文件 ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:2","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"2、初始化密钥文件 docker run \\ -v /data/openvpn:/etc/openvpn \\ --rm -it kylemanna/openvpn:2.4 ovpn_initpki 执行过程中需要先设置ca密码（如123456），Common Name可不设置直接按回车继续，接着需要输入ca密码更新密钥库以及生成crl文件 ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:3","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"3、生成客户端证书 docker run \\ -v /data/openvpn:/etc/openvpn \\ --rm -it kylemanna/openvpn:2.4 easyrsa build-client-full xxxxxxx nopass 其中 xxxxxxx 为自定义名称，生成的过程需要输入ca密码 ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:4","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"4、导出客户端的配置文件openvpn-client.ovpn docker run \\ -v /data/openvpn:/etc/openvpn \\ --rm kylemanna/openvpn:2.4 ovpn_getclient xxxxxxx \u003e /data/openvpn/openvpn-client.ovpn 注意openvpn-client名称需与第三步生成时命名一致，此时生成的配置文件openvpn-client.ovpn即可用于客户端连接 ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:5","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"5、启动openvpn docker run \\ -v /data/openvpn:/etc/openvpn \\ -d -p 1194:1194/udp \\ --restart=always \\ --name openvpn \\ --cap-add=NET_ADMIN \\ --sysctl net.ipv6.conf.all.disable_ipv6=0 \\ --sysctl net.ipv6.conf.default.forwarding=1 \\ --sysctl net.ipv6.conf.all.forwarding=1 \\ kylemanna/openvpn:2.4 ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:6","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"6、开启用户名密码认证 6.1 修改 openvpn.conf 配置文件 修改 运行用户为 root 加入如下内容： ### 用户名密码认证 script-security 3 auth-user-pass-verify /etc/openvpn/checkpsw.sh via-env #指定用户认证脚本 username-as-common-name client-cert-not-required 6.2 创建用户名密码文件 vi /data/openvpn/psw-file 文件内容。注意：一行代表一个用户，前面是用户名后面是密码，用户名和密码用空格隔开 user1 123456 user2 123456 6.3 创建用户认证脚本 vi /data/openvpn/checkpsw.sh 文件内容如下： #!/bin/sh ########################################################### # checkpsw.sh (C) 2004 Mathias Sundman \u003cmathias@openvpn.se\u003e # # This script will authenticate OpenVPN users against # a plain text file. The passfile should simply contain # one row per user with the username first followed by # one or more space(s) or tab(s) and then the password. PASSFILE=\"/etc/openvpn/psw-file\" LOG_FILE=\"/var/log/openvpn-password.log\" TIME_STAMP=`date \"+%Y-%m-%d %T\"` ########################################################### if [ ! -r \"${PASSFILE}\" ]; then echo \"${TIME_STAMP}: Could not open password file \\\"${PASSFILE}\\\" for reading.\" \u003e\u003e ${LOG_FILE} exit 1 fi CORRECT_PASSWORD=`awk '!/^;/\u0026\u0026!/^#/\u0026\u0026$1==\"'${username}'\"{print $2;exit}' ${PASSFILE}` if [ \"${CORRECT_PASSWORD}\" = \"\" ]; then echo \"${TIME_STAMP}: User does not exist: username=\\\"${username}\\\", password=\\\"${password}\\\".\" \u003e\u003e ${LOG_FILE} exit 1 fi if [ \"${password}\" = \"${CORRECT_PASSWORD}\" ]; then echo \"${TIME_STAMP}: Successful authentication: username=\\\"${username}\\\".\" \u003e\u003e ${LOG_FILE} exit 0 fi echo \"${TIME_STAMP}: Incorrect password: username=\\\"${username}\\\", password=\\\"${password}\\\".\" \u003e\u003e ${LOG_FILE} exit 1 注意：PASSFILE 和 LOG_FILE 配置文件和自己的路径要匹配 chmod 777 checkpsw.sh 6.4 重启 openvpn docker容器 docker restart xxx 6.5 修改客户端配置文件，在文件的最后加入： auth-user-pass ","date":"2022-09-02","objectID":"/archives/l0bfx4kv/:0:7","tags":["技巧"],"title":"09-02::Docker部署OpenVPN","uri":"/archives/l0bfx4kv/"},{"categories":["日常记录"],"content":"Docker部署Zabbix ","date":"2022-09-02","objectID":"/archives/mv2jaib0/:0:0","tags":["技巧"],"title":"09-02::Docker部署Zabbix","uri":"/archives/mv2jaib0/"},{"categories":["日常记录"],"content":"一：安装 Zabbix 服务 创建docker网络 docker network create -d bridge zabbix_net 创建zabbix服务，注意数据库配置改为自己的数据库信息，启动时会自动创建 zabbix 数据库 docker run \\ --name zabbix-server \\ -p 10051:10051 \\ -e DB_SERVER_HOST=\"数据库服务Ip\" \\ -e MYSQL_USER=\"数据库用户名\" \\ -e MYSQL_PASSWORD=\"数据库密码\" \\ --network zabbix_net -d zabbix/zabbix-server-mysql 创建zabbix web 服务，注意数据库配置改为自己的数据库信息 docker run --name zabbix-web \\ -p 8089:8080 \\ --link zabbix-server:zabbix-server \\ -e DB_SERVER_HOST=\"数据库服务Ip\" \\ -e MYSQL_USER=\"数据库用户名\" \\ -e MYSQL_PASSWORD=\"数据库密码\" \\ -e ZBX_SERVER_HOST=\"zabbix-server\" \\ -e PHP_TZ=\"Asia/Shanghai\" \\ --network zabbix_net -d zabbix/zabbix-web-nginx-mysql ","date":"2022-09-02","objectID":"/archives/mv2jaib0/:1:0","tags":["技巧"],"title":"09-02::Docker部署Zabbix","uri":"/archives/mv2jaib0/"},{"categories":["日常记录"],"content":"二：安装 Zabbix agent ","date":"2022-09-02","objectID":"/archives/mv2jaib0/:2:0","tags":["技巧"],"title":"09-02::Docker部署Zabbix","uri":"/archives/mv2jaib0/"},{"categories":["日常记录"],"content":"docker 安装形式 docker run -d --name zabbix-agent \\ -e ZBX_HOSTNAME=\"172.19.0.2\" \\ -e ZBX_SERVER_HOST=\"172.19.0.2\" \\ -p 10050:10050 \\ --link zabbix-server:zabbix-server \\ --network zabbix_net zabbix/zabbix-agent:latest ","date":"2022-09-02","objectID":"/archives/mv2jaib0/:2:1","tags":["技巧"],"title":"09-02::Docker部署Zabbix","uri":"/archives/mv2jaib0/"},{"categories":["日常记录"],"content":"rpm包安装形式 rmp 包下载地址：https://repo.zabbix.com/zabbix/ 安装 rpm 包 rpm -Uvh openssl11-libs-1.1.1k-2.el7.x86_64.rpm rpm -Uvh zabbix-agent-5.4.9-1.el8.x86_64.rpm 修改 agent 配置为服务器IP vi /etc/zabbix/zabbix_agentd.conf agent 服务操作 systemctl status zabbix-agent.service systemctl stop zabbix-agent.service systemctl start zabbix-agent.service ","date":"2022-09-02","objectID":"/archives/mv2jaib0/:2:2","tags":["技巧"],"title":"09-02::Docker部署Zabbix","uri":"/archives/mv2jaib0/"},{"categories":["日常记录"],"content":"CAP 理论与 BASE 理论 ","date":"2022-04-27","objectID":"/archives/6a1dd085/:0:0","tags":["技巧"],"title":"04-27::CAP 理论与 BASE 理论","uri":"/archives/6a1dd085/"},{"categories":["日常记录"],"content":"什么是CAP理论 1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。 Consistency（一致性） Availability（可用性） Partition tolerance（分区容错性） Eric Brewer 说：这三个指标不可能同时满足，这个结论就叫做 CAP 定理。 分区容错性（Partition tolerance） ：比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。介于分区状态下，G1 和 G2 是两台跨区的服务器，G1 向 G2 发送一条消息，G2 可能无法收到，因为网络总是不可靠的，因此可以认为P总是成立的。 Availability（可用性） ：只要收到用户的请求，服务器就必须给出回应，但此时由于网络问题会导致服务器之间的数据无法做到实时同步，牺牲了一致性，此时满足AP。 Consistency（一致性） ：用户A访问系统A，用户B访问系统B，系统A和系统B保持同步，当用户A对系统A的data做出更改后，用户B查询系统B的data时，需要查询出用户A操作后的数据，而同步是要通过网络，网络却又总是不可靠的，所以为确保用户B能查询出用户A修改的数据，必须在用户B查询前将系统A的data同步到系统B上，这样就牺牲了可用性，此时满足CP。 ","date":"2022-04-27","objectID":"/archives/6a1dd085/:1:0","tags":["技巧"],"title":"04-27::CAP 理论与 BASE 理论","uri":"/archives/6a1dd085/"},{"categories":["日常记录"],"content":"什么是 BASE 理论 由于CAP中一致性C和可用性A无法兼得，eBay的架构师，提出了BASE理论，它是通过牺牲数据的强一致性，来获得可用性。它有如下3种特征： Basically Available（基本可用）：分布式系统在出现不可预知故障的时候，允许损失部分可用性，保证核心功能的可用。 Soft State（软状态）：软状态也称为弱状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 Eventually consistent（最终一致性）：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 BASE理论并没有要求数据的强一致性，而是允许数据在一定的时间段内是不一致的，但在最终某个状态会达到一致。在生产环境中，很多公司，会采用BASE理论来实现数据的一致，因为产品的可用性相比强一致性来说，更加重要。比如在电商平台中，当用户对一个订单发起支付时，往往会调用第三方支付平台，比如支付宝支付或者微信支付，调用第三方成功后，第三方并不能及时通知我方系统，在第三方没有通知我方系统的这段时间内，我们给用户的订单状态显示支付中，等到第三方回调之后，我们再将状态改成已支付。虽然订单状态在短期内存在不一致，但是用户却获得了更好的产品体验。 END ","date":"2022-04-27","objectID":"/archives/6a1dd085/:2:0","tags":["技巧"],"title":"04-27::CAP 理论与 BASE 理论","uri":"/archives/6a1dd085/"},{"categories":["日常记录"],"content":"Docker搭建Ngrok内网穿透 ","date":"2022-04-20","objectID":"/archives/a010ac2d/:0:0","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"一：准备 要有云服务器一台; 公网域名一个，可以是一级域名也可以是二级域名，我这里使用二级域名ngrok.mydomain.com进行举例； ","date":"2022-04-20","objectID":"/archives/a010ac2d/:1:0","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"二：解析域名 A记录 解析 ngrok.mydomain.com到服务器ip CNAME 解析 *.ngrok.mydomain.com 到 ngrok.mydomain.com ","date":"2022-04-20","objectID":"/archives/a010ac2d/:2:0","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"三：开始搭建 ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:0","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"1.下载镜像 docker pull lumingbao/ngrok ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:1","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"2.启动一个容器生成ngrok客户端,服务器端和CA证书 docker run --rm -it -e DOMAIN=\"ngrok.mydomain.com\" -v /root/ngrok:/myfiles lumingbao/ngrok /bin/sh /build.sh ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:2","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"3.启动Ngrok server docker run -idt --name ngrok-server -v /root/ngrok:/myfiles -p 80:80 -p 443:443 -p 4443:4443 -e DOMAIN='ngrok.mydomain.com' --restart=always lumingbao/ngrok /bin/sh /server.sh ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:3","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"4.创建本地config.yml配置文件，文件内容： server_addr: \"ngrok.mydomain.com:4443\" trust_host_root_certs: false tunnels: client: subdomain: \"test\" proto: https: 80 说明： 1：server_addr 后面的域名为你的域名，端口为启动 ngrok 服务时指定的 4443 映射端口 2：subdomain 为内网穿透域名的前缀 3：https 部分为内网穿透域名的协议，可选 http 和 https 4：https 后面的 80 为你要映射的本地端口 ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:4","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"5.根据平台下载对应的客户端工具并启动 根据你的客户端版本，在 /root/ngrok/bin 目录下，下载对应的客户端文件 ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:5","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"6.启动 ./ngrok -config=config.yml start client 注意：如果linux 启动客户端报错： ./ngrok: /lib/ld-musl-x86_64.so.1: bad ELF interpreter: No such file or directory 解决办法： wget https://copr.fedorainfracloud.org/coprs/ngompa/musl-libc/repo/epel-7/ngompa-musl-libc-epel-7.repo -O /etc/yum.repos.d/ngompa-musl-libc-epel-7.repo yum install -y musl-libc-static ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:6","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"7.Linux下ngrok后台运行 nohup 不支持ngrok的后台运行，这里用 screen 安装screen： yum install screen -y 创建任务: screen -S myngrok “myngrok” 是自定义名称，执行后会自动清屏，不要慌,没事,继续。。。 然后正常启动ngrok，关闭窗口，注意：不要 Ctrl + C，直接关闭当前回话窗口就好了，此时ngrok已经在后台运行了，验证一下就好了。 打开screen任务： screen -r myngrok (myngrok 这个名称就是前面自定义的) ，可以在这选择关闭，Ctrl +C 或者查找进程,直接 kill 进程 ps -ef | grep myngrok ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:7","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"8.nginx 代理配置例子 一般情况下，80 端口和 443 端口不会直接给 ngrok 服务使用，需要用 Nginx 进行代理 server { listen 80; listen [::]:80; keepalive_timeout 70; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name ngrok.lzfsd.com *.ngrok.lzfsd.com; location / { proxy_pass http://localhost:88/; proxy_redirect off; proxy_connect_timeout 1; proxy_send_timeout 120; proxy_read_timeout 120; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #千万不能带80，后面我会告诉你为何 #proxy_set_header Host $http_host:80; proxy_set_header Host $http_host; proxy_set_header X-Nginx-Proxy true; proxy_set_header Connection \"\"; } } server { listen 443 ssl; server_name *.ngrok.lzfsd.com; ssl_certificate /etc/letsencrypt/live/ngrok.lzfsd.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/ngrok.lzfsd.com/privkey.pem; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass https://localhost:444/; proxy_redirect off; proxy_connect_timeout 1; proxy_send_timeout 120; proxy_read_timeout 120; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #千万不能带443，后面我会告诉你为何 #proxy_set_header Host $http_host:443; proxy_set_header Host $http_host; proxy_set_header X-Nginx-Proxy true; proxy_set_header Connection \"\"; } } END ","date":"2022-04-20","objectID":"/archives/a010ac2d/:3:8","tags":["技巧"],"title":"04-20::Docker搭建Ngrok内网穿透","uri":"/archives/a010ac2d/"},{"categories":["日常记录"],"content":"CAS 5.3服务器搭建 ","date":"2022-03-17","objectID":"/archives/78134/:1:0","tags":["技巧"],"title":"CAS 5.3服务器搭建","uri":"/archives/78134/"},{"categories":["日常记录"],"content":"一：CAS5.3 下载 下载地址： GitHub下载地址：https://github.com/apereo/cas-overlay-template 版本选择： 点击下载： ","date":"2022-03-17","objectID":"/archives/78134/:1:1","tags":["技巧"],"title":"CAS 5.3服务器搭建","uri":"/archives/78134/"},{"categories":["日常记录"],"content":"二：CAS5.3 编译 运行构建脚本 切换至cas5.3 源码地址(cas-overlay-template-5.3)，执行如下指令：./build.sh run 编译过程中根据不同系统，可能会有不同的报错，具体按照报错内容处理 备注说明:Windows环境运行build.cmd，Linux环境运行build.sh 运行构建提示错误信息：Caused by: java.io.FileNotFoundException:\\etc\\cas\\thekeystore (系统找不到指定的文件) Caused by: java.io.FileNotFoundException: \\etc\\cas\\thekeystore (系统找不到指定的文件。) at java.io.FileInputStream.open0(Native Method) ~[?:1.8.0_211] at java.io.FileInputStream.open(Unknown Source) ~[?:1.8.0_211] at java.io.FileInputStream.\u003cinit\u003e(Unknown Source) ~[?:1.8.0_211] at java.io.FileInputStream.\u003cinit\u003e(Unknown Source) ~[?:1.8.0_211] at sun.net.www.protocol.file.FileURLConnection.connect(Unknown Source) ~[?:1.8.0_211] at sun.net.www.protocol.file.FileURLConnection.getInputStream(Unknown Source) ~[?:1.8.0_211] at org.apache.tomcat.util.file.ConfigFileLoader.getInputStream(ConfigFileLoader.java:89) ~[tomcat-embed-core-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.SSLUtilBase.getStore(SSLUtilBase.java:197) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.SSLHostConfigCertificate.getCertificateKeystore(SSLHostConfigCertificate.java:206) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.SSLUtilBase.getKeyManagers(SSLUtilBase.java:282) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.SSLUtilBase.createSSLContext(SSLUtilBase.java:246) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.AbstractJsseEndpoint.createSSLContext(AbstractJsseEndpoint.java:98) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.AbstractJsseEndpoint.initialiseSsl(AbstractJsseEndpoint.java:72) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:244) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:1191) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:591) ~[tomcat-coyote-8.5.47.jar!/:8.5.47] at org.apache.catalina.connector.Connector.startInternal(Connector.java:1018) ~[tomcat-catalina-8.5.47.jar!/:8.5.47] ... 21 more 错误产生原因：\\etc\\cas\\thekeystore是生成的密钥文件的，因为这里不使用加密，所以需要将cas的https协议忽略并将http协议设置为允许 解决办法：支持http协议配置 1）在cas-overlay-template-5.3目录下创建src文件夹 2）在src文件夹中，依次创建main\\resources目录，最终结果如下 3）拷贝所需文件 进入cas-overlay-template-5.3\\target\\cas\\WEB-INF\\classes目录将services文件夹与application.properties文件复制到上一步的cas-overlay-template-5.3\\src\\main\\resources文件中，如下截图: 4）修改复制后的application.properties文件 注释ssl 协议相关配置： 文件最末尾加入以下2个配置项，如下图： cas.tgc.secure=false cas.serviceRegistry.initFromJson=true 修改services\\HTTPSandIMAPS-10000001.json 增加http协议配置 再次执行构建脚本 ./build.sh run ","date":"2022-03-17","objectID":"/archives/78134/:1:2","tags":["技巧"],"title":"CAS 5.3服务器搭建","uri":"/archives/78134/"},{"categories":["日常记录"],"content":"三：CAS验证 浏览器访问CAS 打开http://localhost:8443/cas 右边的两个提示框，黄色代表cas server没有使用密钥加密，蓝色提示当前登录账户是静态验证，不影响测试 测试使用默认用户名密码进行登录验证 输入默认用户名casuser与密码Mellon，点击登录按钮 备注说明:默认用户名与密码存储在cas-overlay-template-5.3\\src\\main\\resources\\application.properties文件，cas.authn.accept.users=casuser::Mellon 至此，cas 5.3 服务端搭建成功 ","date":"2022-03-17","objectID":"/archives/78134/:1:3","tags":["技巧"],"title":"CAS 5.3服务器搭建","uri":"/archives/78134/"},{"categories":["日常记录"],"content":"MacOS下制作种子图片、将种子隐藏至图片内 开始动手~ 准备： 环境: Mac os 10.13.5 、工具:iTerm2 、 命令:zip和unzip 第一步 压缩t.mp4文件为test.zip包: zip test.zip t.mp4 第二步 将压缩包写入图片并生成新的图片: cat test.jpg test.zip \u003e private.jpg 第三步 解压图片: unzip private.jpg ","date":"2022-01-10","objectID":"/archives/35543/:1:0","tags":["技巧"],"title":"MacOS下制作种子图片、将种子隐藏至图片内","uri":"/archives/35543/"},{"categories":["工作记录"],"content":"根据银行卡号查询开户行API 该接口由支付宝提供，完全免费 使用该接口可以校验银行卡号并返回银行卡号所属银行等信息 String cardNo = “xxxxx”; https://ccdcapi.alipay.com/validateAndCacheCardInfo.json?_input_charset=utf-8\u0026cardNo=cardNo\u0026cardBinCheck=true { \"cardType\": \"DC\", \"bank\": \"QDCCB\", // 青岛银行 \"key\": \"623170019003xxxxxx\", \"messages\": [], \"validated\": true, \"stat\": \"ok\" } 查看银行卡图片logo，比如查询青岛银行 https://apimg.alipay.com/combo.png?d=cashier\u0026t=QDCCB { \"SRCB\": \"深圳农村商业银行\", \"BGB\": \"广西北部湾银行\", \"SHRCB\": \"上海农村商业银行\", \"BJBANK\": \"北京银行\", \"WHCCB\": \"威海市商业银行\", \"BOZK\": \"周口银行\", \"KORLABANK\": \"库尔勒市商业银行\", \"SPABANK\": \"平安银行\", \"SDEB\": \"顺德农商银行\", \"HURCB\": \"湖北省农村信用社\", \"WRCB\": \"无锡农村商业银行\", \"BOCY\": \"朝阳银行\", \"CZBANK\": \"浙商银行\", \"HDBANK\": \"邯郸银行\", \"BOC\": \"中国银行\", \"BOD\": \"东莞银行\", \"CCB\": \"中国建设银行\", \"ZYCBANK\": \"遵义市商业银行\", \"SXCB\": \"绍兴银行\", \"GZRCU\": \"贵州省农村信用社\", \"ZJKCCB\": \"张家口市商业银行\", \"BOJZ\": \"锦州银行\", \"BOP\": \"平顶山银行\", \"HKB\": \"汉口银行\", \"SPDB\": \"上海浦东发展银行\", \"NXRCU\": \"宁夏黄河农村商业银行\", \"NYNB\": \"广东南粤银行\", \"GRCB\": \"广州农商银行\", \"BOSZ\": \"苏州银行\", \"HZCB\": \"杭州银行\", \"HSBK\": \"衡水银行\", \"HBC\": \"湖北银行\", \"JXBANK\": \"嘉兴银行\", \"HRXJB\": \"华融湘江银行\", \"BODD\": \"丹东银行\", \"AYCB\": \"安阳银行\", \"EGBANK\": \"恒丰银行\", \"CDB\": \"国家开发银行\", \"TCRCB\": \"江苏太仓农村商业银行\", \"NJCB\": \"南京银行\", \"ZZBANK\": \"郑州银行\", \"DYCB\": \"德阳商业银行\", \"YBCCB\": \"宜宾市商业银行\", \"SCRCU\": \"四川省农村信用\", \"KLB\": \"昆仑银行\", \"LSBANK\": \"莱商银行\", \"YDRCB\": \"尧都农商行\", \"CCQTGB\": \"重庆三峡银行\", \"FDB\": \"富滇银行\", \"JSRCU\": \"江苏省农村信用联合社\", \"JNBANK\": \"济宁银行\", \"CMB\": \"招商银行\", \"JINCHB\": \"晋城银行JCBANK\", \"FXCB\": \"阜新银行\", \"WHRCB\": \"武汉农村商业银行\", \"HBYCBANK\": \"湖北银行宜昌分行\", \"TZCB\": \"台州银行\", \"TACCB\": \"泰安市商业银行\", \"XCYH\": \"许昌银行\", \"CEB\": \"中国光大银行\", \"NXBANK\": \"宁夏银行\", \"HSBANK\": \"徽商银行\", \"JJBANK\": \"九江银行\", \"NHQS\": \"农信银清算中心\", \"MTBANK\": \"浙江民泰商业银行\", \"LANGFB\": \"廊坊银行\", \"ASCB\": \"鞍山银行\", \"KSRB\": \"昆山农村商业银行\", \"YXCCB\": \"玉溪市商业银行\", \"DLB\": \"大连银行\", \"DRCBCL\": \"东莞农村商业银行\", \"GCB\": \"广州银行\", \"NBBANK\": \"宁波银行\", \"BOYK\": \"营口银行\", \"SXRCCU\": \"陕西信合\", \"GLBANK\": \"桂林银行\", \"BOQH\": \"青海银行\", \"CDRCB\": \"成都农商银行\", \"QDCCB\": \"青岛银行\", \"HKBEA\": \"东亚银行\", \"HBHSBANK\": \"湖北银行黄石分行\", \"WZCB\": \"温州银行\", \"TRCB\": \"天津农商银行\", \"QLBANK\": \"齐鲁银行\", \"GDRCC\": \"广东省农村信用社联合社\", \"ZJTLCB\": \"浙江泰隆商业银行\", \"GZB\": \"赣州银行\", \"GYCB\": \"贵阳市商业银行\", \"CQBANK\": \"重庆银行\", \"DAQINGB\": \"龙江银行\", \"CGNB\": \"南充市商业银行\", \"SCCB\": \"三门峡银行\", \"CSRCB\": \"常熟农村商业银行\", \"SHBANK\": \"上海银行\", \"JLBANK\": \"吉林银行\", \"CZRCB\": \"常州农村信用联社\", \"BANKWF\": \"潍坊银行\", \"ZRCBANK\": \"张家港农村商业银行\", \"FJHXBC\": \"福建海峡银行\", \"ZJNX\": \"浙江省农村信用社联合社\", \"LZYH\": \"兰州银行\", \"JSB\": \"晋商银行\", \"BOHAIB\": \"渤海银行\", \"CZCB\": \"浙江稠州商业银行\", \"YQCCB\": \"阳泉银行\", \"SJBANK\": \"盛京银行\", \"XABANK\": \"西安银行\", \"BSB\": \"包商银行\", \"JSBANK\": \"江苏银行\", \"FSCB\": \"抚顺银行\", \"HNRCU\": \"河南省农村信用\", \"COMM\": \"交通银行\", \"XTB\": \"邢台银行\", \"CITIC\": \"中信银行\", \"HXBANK\": \"华夏银行\", \"HNRCC\": \"湖南省农村信用社\", \"DYCCB\": \"东营市商业银行\", \"ORBANK\": \"鄂尔多斯银行\", \"BJRCB\": \"北京农村商业银行\", \"XYBANK\": \"信阳银行\", \"ZGCCB\": \"自贡市商业银行\", \"CDCB\": \"成都银行\", \"HANABANK\": \"韩亚银行\", \"CMBC\": \"中国民生银行\", \"LYBANK\": \"洛阳银行\", \"GDB\": \"广东发展银行\", \"ZBCB\": \"齐商银行\", \"CBKF\": \"开封市商业银行\", \"H3CB\": \"内蒙古银行\", \"CIB\": \"兴业银行\", \"CRCBANK\": \"重庆农村商业银行\", \"SZSBK\": \"石嘴山银行\", \"DZBANK\": \"德州银行\", \"SRBANK\": \"上饶银行\", \"LSCCB\": \"乐山市商业银行\", \"JXRCU\": \"江西省农村信用\", \"ICBC\": \"中国工商银行\", \"JZBANK\": \"晋中市商业银行\", \"HZCCB\": \"湖州市商业银行\", \"NHB\": \"南海农村信用联社\", \"XXBANK\": \"新乡银行\", \"JRCB\": \"江苏江阴农村商业银行\", \"YNRCC\": \"云南省农村信用社\", \"ABC\": \"中国农业银行\", \"GXRCU\": \"广西省农村信用\", \"PSBC\": \"中国邮政储蓄银行\", \"BZMD\": \"驻马店银行\", \"ARCU\": \"安徽省农村信用社\", \"GSRCU\": \"甘肃省农村信用\", \"LYCB\": \"辽阳市商业银行\", \"JLRCU\": \"吉林农信\", \"URMQCCB\": \"乌鲁木齐市商业银行\", \"XLBANK\": \"中山小榄村镇银行\", \"CSCB\": \"长沙银行\", \"JHBANK\": \"金华银行\", \"BHB\": \"河北银行\", \"NBYZ\": \"鄞州银行\", \"LSBC\": \"临商银行\", \"BOCD\": \"承德银行\", \"SDRCU\": \"山东农信\", \"NCB\": \"南昌银行\", \"TCCB\": \"天津银行\", \"WJRCB\": \"吴江农商银行\", \"CBBQS\": \"城市商业银行资金清算中心\", \"HBRCU\": \"河北省农村信用社\" } ","date":"2021-12-16","objectID":"/archives/97661/:1:0","tags":["API"],"title":"根据银行卡号查询银行卡信息API","uri":"/archives/97661/"},{"categories":["日常记录"],"content":"激活windows11 1、在桌面新建一个文本文档，把以下代码复制进去: slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GX slmgr /skms kms.03k.org slmgr /ato。 如图所示： 2、点击文件选择“另存为”，在弹出的界面中，将保存位置选择在桌面，保存类型改为所有文件，文件名改为.bat格式的文件，然后点击“保存”按钮 3、右键点击在桌面上双击刚保存的文件，选择【管理员身份运行】，之后会弹出“成功地安装了产品密钥”提示，点击“确定”按钮。 4、接着会弹出“密钥管理服务计算机名称成功设置为kms.xspace.in”提示，点击“确定”按钮。 5、随后就会弹出“成功地激活了产品”提示，点击“确定”按钮。 6、这时我们打开计算机系统属性，就可以看到windows已激活。 ","date":"2021-11-26","objectID":"/archives/26183/:1:0","tags":["激活","windows11"],"title":"激活Windows11","uri":"/archives/26183/"},{"categories":["工作记录"],"content":"使用rsa对密码加密传输(js前端加密，java后台解密) 生成密钥 package cn.lumingbao; import org.bouncycastle.jce.provider.BouncyCastleProvider; import java.security.KeyPair; import java.security.KeyPairGenerator; import java.security.Provider; import java.security.SecureRandom; /** * ============================ * * @ClassName Test * @Description * @Author lumingbao * @Date 2021/11/17 15:56 * ============================ */ public class Test { public static void main(String[] args) throws Exception{ //生产秘钥对 //bouncy castle（轻量级密码术包）是一种用于 Java 平台的开放源码的轻量级密码术包 Provider provider = new BouncyCastleProvider(); KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(\"RSA\", provider); keyPairGen.initialize(1024, new SecureRandom()); KeyPair keyPair = keyPairGen.generateKeyPair(); //打印公钥 System.out.println(keyPair.getPublic()); //打印私钥 System.out.println(keyPair.getPrivate()); } } 以上代码执行得到如下结果： 其中private exponent是私钥用户后台解密不能泄露出去 RSA Public Key 中的modulus和public exponent 公钥用于交给前段js加密 前端：引入js文件 security.js 附上security.js地址：https://oss.lumingbao.cn/security.js html页面中导入此js,以下为js加密代码 //rsa 私钥 var password = 'ceshi'; var key = RSAUtils.getKeyPair('10001', '', '82110fdd17475879d8c853e0c081a3b705985266a066eac23270bb6b7fb3596da5e6aed75a6b3af15a0d2773b6de15d356a2ed427e7d374e9c1d4f639dc4174f2d838492a46a613151b4219955490eb64705474721c22a453d52cece42b31f03ab4811d173ca83cd76566cf287b2dfbdda0706137fbf53915285294cd5b2922f'); //加密后的密码 password = RSAUtils.encryptedString(key, password); console.log(\"password:\" + password); java后台解密 public static void main(String[] args) throws Exception { //js前端加密后的字符串 String Password = \"\"; //RSA Private CRT Key的modulus String hexModulus = \"82110fdd17475879d8c853e0c081a3b705985266a066eac23270bb6b7fb3596da5e6aed75a6b3af15a0d2773b6de15d356a2ed427e7d374e9c1d4f639dc4174f2d838492a46a613151b4219955490eb64705474721c22a453d52cece42b31f03ab4811d173ca83cd76566cf287b2dfbdda0706137fbf53915285294cd5b2922f\"; //RSA Private CRT Key的private exponent String hexPrivateExponent = \"3eb7df806b233a24b746123c4457bf0c182495476b7d752263943cabdf8e2a4757425f78f4ded433618b0a45201f03433f799d12fd4f8005e5fdb43482f4f58fc4ef0a9a72329658463042aa3febf42e5b8aa02c0ac3e4f6bc481e912c2afad8dfda9d75ffacfded25083b1bc8b2d86fcc3bcd3845824943c7f9d35c3e4cc211\"; Provider provider = new BouncyCastleProvider(); KeyFactory keyFac = KeyFactory.getInstance(\"RSA\", provider); RSAPrivateKeySpec priKeySpec = new RSAPrivateKeySpec(new BigInteger(hexModulus, 16), new BigInteger(hexPrivateExponent, 16)); // 生成用于解密的私钥 RSAPrivateKey pk = (RSAPrivateKey) keyFac.generatePrivate(priKeySpec); // 解密 Cipher cipher = Cipher.getInstance(\"RSA\", provider); cipher.init(2, pk); byte[] pwd = cipher.doFinal(Hex.decodeHex(Password.toCharArray())); Password = StringUtils.reverse(new String(pwd)); System.out.println(\"解密后：\" + Password); } 未完待续…… ","date":"2021-11-22","objectID":"/archives/16805/:1:0","tags":["加解密"],"title":"使用rsa对密码加密传输(js前端加密，java后台解密)","uri":"/archives/16805/"},{"categories":["日常记录"],"content":"MacOS 移动硬盘中的文件灰色不可用处理办法 有时候在苹果电脑上插入移动硬盘，会发现有些文件灰色状态不可用，也不能进行复制，可以用这个办法进行暂时解决 打开终端执行如下命令： xattr -d com.apple.FinderInfo * 注意：*号部分替换为文件目录，或者文件所在目录 ","date":"2021-09-18","objectID":"/archives/57323/:1:0","tags":["MacOS"],"title":"MacOS 移动硬盘中的文件灰色不可用处理办法","uri":"/archives/57323/"},{"categories":["工作记录"],"content":"mysqldump 导出 数据+结构+函数+存储过程 ","date":"2021-03-24","objectID":"/archives/52346/:1:0","tags":["MySQL"],"title":"mysqldump 导出 数据+结构+函数+存储过程","uri":"/archives/52346/"},{"categories":["工作记录"],"content":"MySQL导出： 导出单个数据库：结构 无数据 [root@localhost ~]#mysqldump -h127.0.0.1 -uroot -p --opt --no-data db_name \u003e~/db_name.sql 导出单个数据库：有数据 无结构 [root@localhost ~]#mysqldump -h127.0.0.1 -uroot -p --opt --no-create-info db_name \u003e~/db_name.sql 导出单个数据库：结构+数据 [root@localhost ~]#mysqldump -h127.0.0.1 -uroot -p --opt db_name \u003e~/db_name.sql 导出单个数据库：结构+数据+函数+存储过程 [root@localhost ~]#mysqldump -h127.0.0.1 -uroot -p --opt -R db_name \u003e~/db_name.sql 导出多个数据库：结构 [root@localhost ~]#mysqldump -h127.0.0.1 -uroot -p --opt --databases db_name1 db_name2 \u003e~/db_name.sql 导出单个表：结构 无数据 [root@localhost ~]#mysqldump -h127.0.0.1 -uroot -p --opt --no-data -d db_name table\u003e~/table_name.sql 导出单个表：结构 包含数据 [root@localhost ~]#mysqldump -h127.0.0.1 -uroot -p --opt dbname tablename\u003e～/tablename.sql ","date":"2021-03-24","objectID":"/archives/52346/:1:1","tags":["MySQL"],"title":"mysqldump 导出 数据+结构+函数+存储过程","uri":"/archives/52346/"},{"categories":["工作记录"],"content":"MySQL导入： [root@localhost ~]# mysql -u root -p [root@localhost ~]# use 要导入的数据库 [root@localhost ~]#source /home/1.sql 或者 [root@localhost ~]# mysql -u root -p\u003c /home/1.sql ","date":"2021-03-24","objectID":"/archives/52346/:1:2","tags":["MySQL"],"title":"mysqldump 导出 数据+结构+函数+存储过程","uri":"/archives/52346/"},{"categories":["工作记录"],"content":"MacOS Linux下Mysql每天自动备份的实现 新建目录 mkdir -p /data/mysqlbak/data mkdir -p /data/mysqlbak/scripts mkdir -p /data/mysqlbak/logs 创建备份脚本 cd /data/mysqlbak/scripts vi backup.sh #!/bin/bash #备份目录 BACKUP_ROOT=/data/mysqlbak BACKUP_FILEDIR=$BACKUP_ROOT/data #当前日期 DATE=$(date +%Y%m%d) ######备份###### #查询所有数据库 #-uroot -p123456表示使用root账号执行命令，且root账号的密码为:123456 DATABASES=$(mysql -uroot -p123456 -e \"show databases\" | grep -Ev \"Database|sys|information_schema|performance_schema|mysql\") #循环数据库进行备份 for db in $DATABASES do echo echo ----------$BACKUP_FILEDIR/${db}_$DATE.sql.gz BEGIN---------- mysqldump -uroot -p123456 --default-character-set=utf8 -q --lock-all-tables --flush-logs -E -R --triggers -B ${db} | gzip \u003e $BACKUP_FILEDIR/${db}_$DATE.sql.gz echo ----------$BACKUP_FILEDIR/${db}_$DATE.sql.gz COMPLETE---------- echo done echo \"done\" 设置脚本的执行权限 chmod 777 backup.sh 将备份操作加入到定时任务(每天凌晨2点定时执行) crontab -e 00 2 * * * /data/mysqlbak/scripts/backup.sh \u003e data/mysqlbak/logs/backup.log 2\u003e\u00261 创建删除脚本(定时删除7天前的备份数据) vi backup_clean.sh #!/bin/bash echo ----------CLEAN BEGIN---------- find /data/mysqlbak/data -mtime +7 -name \"*.gz\" -exec rm -rf {} \\; echo ----------CLEAN COMPLETE---------- 设置脚本的执行权限 chmod 777 backup_clean.sh 将删除操作加入到定时任务(每天凌晨1点定时执行) 00 1 * * * /data/mysqlbak/scripts/backup_clean.sh \u003e /data/mysqlbak/logs/backup_full_clean.log 2\u003e\u00261 查看定时任务 crontab -l 如果需要备份到另外一台机器，可以备份完scp到另外一台机器 首先服务器需要安装export，yum安装： yum install expect 或者源码安装，参考：https://www.cnblogs.com/operationhome/p/9154055.html 脚本修改： #!/bin/bash #备份目录 BACKUP_ROOT=/data/mysqlbak BACKUP_FILEDIR=$BACKUP_ROOT/data #当前日期 DATE=$(date +%Y%m%d) ######备份###### #查询所有数据库 #-uroot -p123456表示使用root账号执行命令，且root账号的密码为:123456 DATABASES=$(mysql -uroot -p123456 -e \"show databases\" | grep -Ev \"Database|sys|information_schema|performance_schema|mysql\") #循环数据库进行备份 for db in $DATABASES do echo echo ----------$BACKUP_FILEDIR/${db}_$DATE.sql.gz BEGIN---------- mysqldump -uroot -p123456 --default-character-set=utf8 -q --lock-all-tables --flush-logs -E -R --triggers -B ${db} | gzip \u003e $BACKUP_FILEDIR/${db}_$DATE.sql.gz echo ----------$BACKUP_FILEDIR/${db}_$DATE.sql.gz COMPLETE---------- echo ----------scp 226 begin---------- expect -c \" spawn scp -r /data/mysqlbak/data/${db}_$DATE.sql.gz root@xxx.xxx.xxx.226:/data/mysqlbak/data225/ expect { \\\"*assword\\\" {set timeout 300; send \\\"此处是scp的密码\\r\\\"; exp_continue;} \\\"yes/no\\\" {send \\\"yes\\r\\\";} } expect eof\" echo ----------scp 226 end---------- echo done echo \"done\" ","date":"2021-01-05","objectID":"/archives/75275/:1:0","tags":["Linux","MySQL"],"title":"Linux下Mysql每天自动备份的实现","uri":"/archives/75275/"},{"categories":["工作记录"],"content":"Centos下安装JDK 查看是否配置了jdk：java -version 查看是否安装openjdk命令 ： rpm -qa | grep jdk 卸载jdk ： yum -y remove java-1.6.0-openjdk-1.6.0.0-1.45.1.11.1.el6.i686 （后面部分为使用查看命令得到的名称） 查看环境变量：echo $PATH 解压： tar -zxvf jdk-8u131-linux-x64.gz JAVA环境变量： vi /etc/profile export JAVA_HOME=/usr/java/jdk1.8.0_131 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATH export PATH=$JAVA_HOME/bin:$PATH 按Esc键盘，输入 :wq保存退出后 在输入指令：source /etc/profile 使设置的环境变量生效。 再输入 ： java -version 查看版本信息，验证jdk是否安装成功。 ","date":"2020-01-28","objectID":"/archives/93072/:1:0","tags":["CentOS","JDK"],"title":"CentOS安装JDK","uri":"/archives/93072/"},{"categories":["SpringBoot"],"content":"SpringBoot 集成ElasticSearch 一：安装ElasticSearch ElasticSearch简介：分布式索引。 ElasticSearch与MySql 关系： DB type –\u003e Table Document –\u003e row ElasticSearch已有5.x版本，然而Spring Data 目前只支持ElasticSearch2.X版本，支持说明：https://github.com/spring-projects/spring-data-elasticsearch/wiki/Spring-Data-Elasticsearch—Spring-Boot—version-matrix 手动安装Elasticsearch Linux下无法用root用户启动 ElasticSearch，创建 elasticsearch用户，命令如下： [root@slave2 ~] useradd es [root@slave2 ~] passwd es 获取ElasticSearch，地址：https://www.elastic.co/downloads/past-releases 安装ElasticSearch： 解压，修改config下的elasticsearch.yml 配置 : cluster.name: elasticsearch #这是集群名字，我们起名为 elasticsearch。es启动后会将具有相同集群名字的节点放到一个集群下。 node.name: node-1 network.host: 192.168.20.110 discovery.zen.minimum_master_nodes: 1 修改用户权限，使用root用户执行如下命令： chown -R 用户名 elasticsearch-2.4.0 运行： 进入 bin 目录，执行 ./elasticsearch 没有报错启动成功，访问 IP:9200，提示json信息，表示运行成功。 自动安装Elasticsearch 1．下载 elasticsearch rpm 安装包，上传至linux 相应目录下，执行安装命令： yum install elasticsearch.rmp 2.安装完毕以后查看安装目录，命令： rpm -ql elasticsearch 3.修改配置文件 vi /etc/sysconfig/elasticsearch 加入 JAVA_HOME=” /usr/java/jdk1.8.0_131” 指定jdk目录,因为service 脚本无法读取 JAVA_HOME环境变量 4.执行启动命令： service elasticsearch start 查看启动状态： service elasticsearch status 5.设置开机启动，命令： chkconfig elasticsearch on 6.修改配置文件，使外部可以访问： vi /etc/elasticsearch/elasticsearch.yml 二：服务化Elasticsearch 完成了上述步骤以后，直接可以使用脚本启动服务.但是使用起来不是很方便.比如我们的日志是直接打印到了控制台上了.退出后 ElasticSearch 直接就退出了.不太好使.因此需要进行一些处理. ElasticSearch 守护进程 java-service-wrapper 在 2.x 使用的解决方法。 elasticsearch-1.x 版本直接使用：https://github.com/elastic/ela … apper 则没什么问题，按照向导启动即可，最近在弄elasticsearch-2.0 时，直接把 1.x 下的守护程序 copy 过来后，启动出现问题。其中几个变化有： es 不再使用 sigar 来进行监控系统资源了(这里对守护程序无影响)。 elasticsearch 的启动类从 org.elasticsearch.bootstrap.ElasticsearchF 变更到 org.elasticsearch.bootstrap.Elasticsearch，并且在后续版本删除了 ElasticsearchF 类。 为了安全，不再建议使用 root 权限来运行 es。 这里我目前的解决方案是依然使用 root 权限来启动，非 root 用户下启动暂未验证。方法如下： 既然 sigar 没了，先注释掉 sigar。 改变启动类为: wrapper.app.parameter.1=org.elasticsearch.bootstrap.Elasticsearch wrapper.app.parameter.2=start 允许 root 用户运行，并禁止掉类权限验证： wrapper.java.additional.1=-Des.insecure.allow.root=true wrapper.java.additional.2=-Des.security.manager.enabled=false 注：希望有非 root 用户下运行该守护程序的解决方案的同学提供下解决方法，在此不胜感激。 此方法降低了安全性，大家慎重考虑。 不喜欢折腾的同学直接使用 rpm 安装即可。 服务化 ElasticSearch 是使用的是一个 开源的 ServiceWrapper 脚本完成了.这个脚本的 ElasticSearch 的官方开发人员提供的. 下载插件 GitHub 地址: https://github.com/elastic/elasticsearch-servicewrapper 下载zip文件，解压到指定目录，命令：unzip service.zip 执行拷贝命令将service目录拷贝到 elasticsearch 安装目录下bin目录下的service cp -r ~/master/elasticsearch-servicewrapper-master/service/ /home/q/elasticsearch172/bin/service 修改elasticsearch.conf 设置 ES_HOME:/sur/elasticsearch/elasticsearch-2.4.5/ 安装服务，进入service目录执行： 给 elasticsearch 文件给执行权限命令： chmod a+x elasticsearch 执行： elasticsearch install 启动服务： service elasticsearch start chmod命令详解： chmod [ugoa] [+(加入)-(除去)=(设定)] [rwx] 文件或目录 u 表示“用户（user）”，即文件或目录的所有者。 g 表示“同组（group）用户”，即与文件属主有相同组ID的所有用户。 o 表示“其他（others）用户”。 a 表示“所有（all）用户”。它是系统默认值。 r 可读。 w 可写。 x 可执行。 三：插件及其安装 BigDesk Plugin : 对集群中es状态进行监控。 Elasticsearch Head Plugin: 对ES进行各种操作，如查询、删除、浏览索引等。 1.安装head插件 https://github.com/mobz/elasticsearch-head下载zip 解压 建立elasticsearch-2.4.0\\plugins\\head文件 将解压后的elasticsearch-head-master文件夹下的文件copy到head cp -r elasticsearch-head-master/* /usr/share/elasticsearch/plugins/head 运行es 访问：http://ip:9200/_plugin/head/ 2.安装bigdesk 下载bigdesk插件包 https://github.com/lukas-vlcek/bigdesk 下载master.zip后解压 建立elasticsearch-2.x\\plugins\\bigdesk_site文件夹 将解压后的bigdesk-master文件夹下的文件copy到_site 在plugin\\bigdesk下创建 plugin-descriptor.properties vim plugin-descriptor.properties 添加以下内容: description=bigdesk - A web front end for an elastic search cluster version=master site=true name=bigdesk vim _site/js/store/BigdeskStore.js 定位到142行 去掉major == 1条件 重启es，访问http://ip:9200/_plugin/bigdesk/ 四：Springboot集成ES pom.xml 引用相关依赖： \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-elasticsearch\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.data\u003c/groupId\u003e \u003cartifactId\u003espring-data-elasticsearch\u003c/arti","date":"2020-01-28","objectID":"/archives/47730/:1:0","tags":["SpringBoot","ElasticSearch"],"title":"SpringBoot 集成ElasticSearch","uri":"/archives/47730/"},{"categories":["日常记录"],"content":"Mac下制作Win10启动盘 准备： U盘一个，16G以上即 微软官方的ISO镜像 1：使用MacOS自带的磁盘工具，将U盘抹掉,并将名称改为 WINDOWS10 格式为：ExFAT: 2：之后双击下载的Windows安装盘镜像，此时该Volume的名称应该为（为Windows 10的话）CCCOMA_X64FRE_EN-US_DV9 （英文镜像）或者CCCOMA_X64FRE_ZH-CN_DV9 （中文镜像） 3：输入下列命令并将VolumeName换成你的镜像的名字，比如中文的镜像话就换成CCCOMA_X64FRE_ZH-CN_DV9： cp -rp /Volumes/VolumeName/* /Volumes/WINDOWS10/ 等待完成即可 ","date":"2019-06-22","objectID":"/archives/33551/:1:0","tags":["Mac","Windows10"],"title":"Mac下制作Win10启动盘","uri":"/archives/33551/"},{"categories":["黑苹果"],"content":"黑苹果电量显示教程 1.提取DSDT，开机四叶草引导界面按下F4，没有任何提示。直接选择系统开机。 2.开机后用Clover Configurator挂载 EFI 分区，在clover/acpi/origin目录下找到DSDT.aml 3.安装Maciasl，并用Maciasl打开前面找到的 DSDT.aml 文件。 4.在Preferences 中，将ACPI设置为4.0，如下图所示： 5.点击 Compile 检查错误，如果有错误，修改错误，具体修改方法请根据具体错误百度。 我遇到的一个错误，错图提示如下图所示： 修改方法如下图所示： 6.错误修改完成的情况下，点击Patch，在弹出的左侧菜单中找到自己对应或者同品牌的电脑型号，点击apply，如果apply被遮住，可以拖动弹出的窗口大小，然后保存文件。 7.将文件复制到 origin 同级的 patched 文件夹下，如下图所示，重启电脑，如果没有问题，就可以看到电池电量正常显示了。 ","date":"2019-05-29","objectID":"/archives/07602/:1:0","tags":["黑苹果"],"title":"黑苹果电量显示教程","uri":"/archives/07602/"},{"categories":["工作记录"],"content":"CentOS安装FastDFS ","date":"2018-03-12","objectID":"/archives/16739/:1:0","tags":["CentOS","FastDFS"],"title":"CentOS安装FastDFS","uri":"/archives/16739/"},{"categories":["工作记录"],"content":"FastDfs分布式文件系统 ","date":"2018-03-12","objectID":"/archives/16739/:1:1","tags":["CentOS","FastDFS"],"title":"CentOS安装FastDFS","uri":"/archives/16739/"},{"categories":["工作记录"],"content":"一：简介 FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。 FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。 首先简单了解一下基础概念，FastDFS是一个开源的轻量级分布式文件系统，由跟踪服务器（tracker server）、存储服务器（storage server）和客户端（client）三个部分组成，主要解决了海量数据存储问题，特别适合以中小文件（建议范围：4KB \u003c file_size \u003c500MB）为载体的在线服务。FastDFS的系统结构图如下： 如上图，FastDFS的两个核心概念分别是： 1.Tracker（跟踪器） 2.Storage（存储节点） Tracker主要做调度工作，相当于mvc中的controller的角色，在访问上起负载均衡的作用。跟踪器和存储节点都可以由一台或多台服务器构成，跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务，其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。Tracker负责管理所有的Storage和group，每个storage在启动后会连接Tracker，告知自己所属的group等信息，并保持周期性的心跳，tracker根据storage的心跳信息，建立group==\u003e[storage server list]的映射表，Tracker需要管理的元信息很少，会全部存储在内存中；另外tracker上的元信息都是由storage汇报的信息生成的，本身不需要持久化任何数据，这样使得tracker非常容易扩展，直接增加tracker机器即可扩展为tracker cluster来服务，cluster里每个tracker之间是完全对等的，所有的tracker都接受stroage的心跳信息，生成元数据信息来提供读写服务。 Storage采用了分卷[Volume]（或分组[group]）的组织方式，存储系统由一个或多个组组成，组与组之间的文件是相互独立的，所有组的文件容量累加就是整个存储系统中的文件容量。一个卷[Volume]（组[group]）可以由一台或多台存储服务器组成，一个组中的存储服务器中的文件都是相同的，组中的多台存储服务器起到了冗余备份和负载均衡的作用，数据互为备份，存储空间以group内容量最小的storage为准，所以建议group内的多个storage尽量配置相同，以免造成存储空间的浪费。更多原理性的内容可以参考这篇文章，介绍的很详细：分布式文件系统FastDFS设计原理http://www.linuxidc.com/Linux/2014-10/107591.htm。 ","date":"2018-03-12","objectID":"/archives/16739/:1:2","tags":["CentOS","FastDFS"],"title":"CentOS安装FastDFS","uri":"/archives/16739/"},{"categories":["工作记录"],"content":"二：安装FastDFS 1：准备 下载地址：https://github.com/happyfish100/fastdfs/releases 由于FastDFS是纯C语言实现，只支持Linux、FreeBSD等UNIX系统，所以我们直接下载tar.gz的压缩包，同时FastDFS 5.0.5同以前版本相比将公共的一些函数等单独封装成了libfastcommon包，所以在安装FastDFS之前我们还必须安装libfastcommon，在GitHub首页可以看到： 将下载好的 fastdfs 的包和 libfastcommon 包上传到指定目录 (如:可新建/usr/software文件夹,用于存放上传的压缩包文件) 使用 tar -zxvf 命令解压 tar.gz 包 使用 unzip 解压 zip 包 如果unzip命令不存在，使用命令：yum -y install unzip zip 安装 2：安装 libfastcommon 使用cd 命令进入解压好的包中，分别执行 ：./make.sh和./make.sh install 如果提示找不到gcc 命令，使用命令：yum -y install gcc-c++ 安装 ./make.sh 为编译命令，没有error信息的话就说明编译成功了 ./make.sh install 为安装命令，看到类似如下提示信息就说明libfastcommon已安装成功 至此libfastcommon就已经安装成功了，但注意一下上图中红色框标注的内容，libfastcommon.so 默认安装到了/usr/lib64/libfastcommon.so，但是FastDFS主程序设置的lib目录是/usr/local/lib，所以此处需要重新设置软链接（类似于Windows的快捷方式）： 分别执行：.. ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 3：安装FastDFS 进入解压的 fastdfs 目录、依次执行： ./make.sh 编译命令 ./make.sh install 安装命令 没有报错就说明安装成功了，在log中我们可以发现安装路径： 没错，正是安装到了/etc/fdfs中。 进入解压的fastdfs 目录下的 conf目录中，将 http.conf anti-steal.jpg mime.types 这三个文件拷贝到 /etc/fdfs目录下，命令如下： cd fastdfs-5.10/conf cp http.conf anti-steal.jpg mime.types /etc/fdfs/ 创建配置文件： cp -p /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf cp -p /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf cp -p /etc/fdfs/client.conf.sample /etc/fdfs/client.conf 至此FastDFS已经安装完毕，接下来的工作就是依次配置Tracker和Storage了。 4：配置Tracker 在配置Tracker之前，首先需要创建Tracker服务器的文件路径，即用于存储Tracker的数据文件和日志文件等，我这里选择在/usr/fastdfs目录下创建一个fastdfs_tracker目录用于存放Tracker服务器的相关文件： mkdir /usr/fastdfs/fastdfs_tracker 修改tracker进程的配置文件/etc/fdfs/tracker.conf disabled=false #启用配置文件（默认启用） port=22122 #设置tracker的端口号，通常采用22122这个默认端口 base_path=/usr/fastdfs/fastdfs_tracker #设置tracker的数据文件和日志目录 http.server_port=6666 #设置http端口号，默认为8080 这里需要配置防火墙例外 22122 端口，6666端口，具体情况视自己配置而定。 配置完成后就可以启动Tracker服务器了，但首先依然要为启动脚本创建软引用，因为fdfs_trackerd等命令在/usr/local/bin中并没有，而是在/usr/bin路径下： ln -s /usr/bin/fdfs_trackerd /usr/local/bin ln -s /usr/bin/stop.sh /usr/local/bin ln -s /usr/bin/restart.sh /usr/local/bin 最后通过命令启动Tracker服务器： service fdfs_trackerd start 命令执行后可以看到以下提示： 如果启动命令执行成功，那么同时在刚才创建的tracker文件目录/usr/fastdfs/fastdfs_tracker中就可以看到启动后新生成的data和logs目录，tracker服务的端口也应当被正常监听，最后再通过netstat命令查看一下端口监听情况： netstat -unltp|grep fdfs 可以看到tracker服务运行的22122端口正常被监听： 确认tracker正常启动后可以将tracker设置为开机启动: chkconfig fdfs_trackerd on Tracker至此就配置好了，接下来就可以配置FastDFS的另一核心——Storage。 5：配置Storage 同理，步骤基本与配置Tracker一致，首先是创建Storage服务器的文件目录，需要注意的是同Tracker相比我多建了一个目录，因为Storage还需要一个文件存储路径，用于存放接收的文件： mkdir /usr/fastdfs/fastdfs_storage mkdir /usr/fastdfs/fastdfs_storage_data 接下来修改/etc/fdfs目录下的storage.conf配置文件，打开文件后依次做以下修改： disabled=false #启用配置文件（默认启用） group_name=group1 #组名，根据实际情况修改 port=23000 #设置storage的端口号，默认是23000，同一个组的storage端口号必须一致 base_path=/usr/fastdfs/fastdfs_storage #设置storage数据文件和日志目录 store_path_count=1 #存储路径个数，需要和store_path个数匹配 store_path0=/usr/fastdfs/fastdfs_storage_data #实际文件存储路径 tracker_server=192.168.20.110:22122 #tracker 服务器的 IP地址和端口号，如果是单机搭建，IP不要写127.0.0.1，否则启动不成功（此处的ip是我的CentOS虚拟机ip） http.server_port=8888 #设置 http 端口号 这里需要配置防火墙例外 23000 端口，8888端口，具体情况视自己配置而定。 配置完成后同样要为Storage服务器的启动脚本设置软引用： ln -s /usr/bin/fdfs_storaged /usr/local/bin 接下来就可以启动Storage服务了： service fdfs_storaged start 命令执行后可以看到以下提示： 同理，如果启动成功，/usr/fastdfs/fastdfs_storage中就可以看到启动后新生成的data和logs目录，端口23000也应被正常监听，还有一点就是文件存储路径下会生成多级存储目录，那么接下来看看是否启动成功了： netstat -unltp|grep fdfs 说明启动成功。 如上图，可以看到/suer/fastdfs/fastdfs_storage/data目录下生成好的pid文件和dat文件，那么再看一下实际文件存储路径下是否有创建好的多级目录呢： 如上图，没有任何问题，data下有256个1级目录，每级目录下又有256个2级子目录，总共65536个文件，新写的文件会以hash的方式被路由到其中某个子目录下，然后将文件数据直接作为一个本地文件存储到该目录中。 设置开机启动： chkconfig fdfs_storaged on 至此storage服务器就已经配置完成，确定了storage服务器启动成功后，还有一项工作就是看看storage服务器是否已经登记到 tracker服务器（也可以理解为tracker与storage是否整合成功），运行以下命令： /usr/bin/fdfs_monitor /etc/fdfs/storage.conf 如上所示，看到192.168.20.110 ACTIVE 字样即可说明storage服务器已经成功登记到了tracker服务器。 至此我们就已经完成了fastdfs的全部配置","date":"2018-03-12","objectID":"/archives/16739/:1:3","tags":["CentOS","FastDFS"],"title":"CentOS安装FastDFS","uri":"/archives/16739/"},{"categories":["工作记录"],"content":"三：Nginx安装和配置 1：准备 4.0.5版本开始移除了自带的HTTP支持（因为之前自带的HTTP服务较为简单，无法提供负载均衡等高性能服务），所以余大提供了nginx上使用FastDFS的模块fastdfs-nginx-module，下载地址如下： https://github.com/happyfish100/fastdfs-nginx-module 这样做最大的好处就是提供了HTTP服务并且解决了group中storage服务器的同步延迟问题，接下来就具体记录一下fastdfs-nginx-module的安装配置过程。 fastdfs-nginx-module 首先将nginx和fastdfs-nginx-module的安装包上传至CentOS (注意:在此我们将压缩包上传至/usr/nginx文件夹下) 在安装nginx之前需要先安装一些模块依赖的lib库 yum -y install pcre pcre-devel yum -y install zlib zlib-devel yum -y install openssl openssl-devel 依次装好这些依赖之后就可以开始安装nginx了。 2：Storage Nginx安装配置 首先为storage服务器安装nginx 分别解压，进入nginx目录执行： ./configure --prefix=/usr/nginx --add-module=/usr/nginx/fastdfs-nginx-module-master/src (注意: /usr/nginx/fastdfs-nginx-module-master/src 该路径为fastdfs-nginx-module-master.zip压缩包解压后所在的文件路径) 配置成功后会看到如下信息： 紧接着就可以进行编译安装了，依次执行以下命令： make make install 如果没有报错，安装正常结束。 安装完成后，我们在我们指定的目录/usr/nginx中就可以看到nginx的安装目录了： cp /usr/nginx/fastdfs-nginx-module-master/src/mod_fastdfs.conf /etc/fdfs/ (注意: /usr/nginx/fastdfs-nginx-module-master/src/mod_fastdfs.conf 该文件为fastdfs-nginx-module-master.zip解压后文件所在的路径) 修改拷贝过去的mod_fastdfs.conf，命令： vi /etc/fdfs/mod_fastdfs.conf base_path=/usr/fastdfs/fastdfs_storage tracker_server=192.168.20.110:22122 group_name=group1 url_have_group_name = true store_path0=/usr/fastdfs/fastdfs_storage_data 接下来要修改一下nginx的配置文件，进入conf目录并打开nginx.conf文件加入以下配置： server { listen 80; server_name localhost; location ~/group[0-9]/M00 { ngx_fastdfs_module; } } 进入nginx下的sbin目录，执行 ./nginx 启动nginx Nginx常用命令: 查看进程:ps -ef | grep nginx 启动: /usr/nginx/sbin/nginx 重启: /usr/nginx/sbin/nginx -s reload 关闭: /usr/nginx/sbin/nginx -s stop 访问文件路径：（此处的文件是我刚才上传的文件哦!）http://192.168.1.11/group1/M00/00/00/wKgBC1qjdjKADXHiAABqAsOwqcU728.jpg 这样一来，下载来的文件名为生成的索引，而不是原文件名。 访问文件强制下载(传参自定义文件名字): 在nginx的 nginx.conf 的 location 节点下加入: add_header Content-Disposition \"attachment;filename=$arg_attname\"; 如图所示: 访问文件地址的时候，在文件后缀加入?attname=filename.jpg 如： http://192.168.1.11/group1/M00/00/00/wKgBC1qjdjKADXHiAABqAsOwqcU728.jpg?attname=new.jpg Nginx 注册为服务 创建nginx启动命令脚本： vi /etc/init.d/nginx 插入以下内容, 注意修改PATH和NAME字段, 匹配自己的安装路径 #! /bin/bash # chkconfig: 2345 80 90 PATH=/usr/nginx DESC=\"nginx daemon\" NAME=nginx DAEMON=$PATH/sbin/$NAME CONFIGFILE=$PATH/conf/$NAME.conf PIDFILE=$PATH/logs/$NAME.pid SCRIPTNAME=/etc/init.d/$NAME set -e [ -x \"$DAEMON\" ] || exit 0 do_start() { $DAEMON -c $CONFIGFILE || echo -n \"nginx already running\" } do_stop() { $DAEMON -s stop || echo -n \"nginx not running\" } do_reload() { $DAEMON -s reload || echo -n \"nginx can't reload\" } case \"$1\" in start) echo -n \"Starting $DESC: $NAME\" do_start echo \".\" ;; stop) echo -n \"Stopping $DESC: $NAME\" do_stop echo \".\" ;; reload|graceful) echo -n \"Reloading $DESC configuration...\" do_reload echo \".\" ;; restart) echo -n \"Restarting $DESC: $NAME\" do_stop do_start echo \".\" ;; *) echo \"Usage: $SCRIPTNAME {start|stop|reload|restart}\" \u003e\u00262 exit 3 ;; esac exit 0 设置执行权限： chmod a+x /etc/init.d/nginx 注册成服务： chkconfig --add nginx 检查mysqld服务是否已经生效 chkconfig --list nginx 设置开机启动： chkconfig nginx on 重启, 查看nginx服务是否自动启动 netstat -apn|grep nginx ","date":"2018-03-12","objectID":"/archives/16739/:1:4","tags":["CentOS","FastDFS"],"title":"CentOS安装FastDFS","uri":"/archives/16739/"},{"categories":["设计模式"],"content":"JAVA生产者消费者模式 ","date":"2018-03-12","objectID":"/archives/98162/:1:0","tags":["设计模式","JAVA"],"title":"JAVA生产者消费者模式","uri":"/archives/98162/"},{"categories":["设计模式"],"content":"一：什么是生产者消费者问题 生产者消费者问题（Producer-consumer problem），也称有限缓冲问题（Bounded-buffer problem），是一个多线程同步问题的经典案例。生产者生成一定量的数据放到缓冲区中，然后重复此过程；与此同时，消费者也在缓冲区消耗这些数据。生产者和消费者之间必须保持同步，要保证生产者不会在缓冲区满时放入数据，消费者也不会在缓冲区空时消耗数据。不够完善的解决方法容易出现死锁的情况，此时进程都在等待唤醒。 示意图： 便于更好的理解举个例子： 以开小卖部为例，老板要去进货，客户要从小卖部买东西，这个时候，老板就是生产者，客户就是消费者， 如果老板进货的速度小于客户买东西的速度，那么当仓库的货物卖完以后，就会出现消费者没有东西可买的情况； 如果老板进货的速度大于消费者消费的速度，那么仓库里的货物会越堆越多，把仓库撑爆。 所以这个时候就需要一种同步机制，当仓库的货物不足的时候去进货，当货物达到一定的量以后，暂停进货，消费者开始消费，仓库的货物不足时暂停消费，开始进货，循环往复。 ","date":"2018-03-12","objectID":"/archives/98162/:1:1","tags":["设计模式","JAVA"],"title":"JAVA生产者消费者模式","uri":"/archives/98162/"},{"categories":["设计模式"],"content":"二：下面介绍JAVA实现生产者消费者模型的四种方法： 1、wait()和notify()方法的实现 这是最简单最基础的实现，缓冲区满和为空时都调用wait()方法等待，当生产者生产了一个产品或者消费者消费了一个产品之后会唤醒所有线程。 当缓冲区已满时，生产者线程停止执行，放弃锁，使自己处于等状态，让其他线程执行； 当缓冲区已空时，消费者线程停止执行，放弃锁，使自己处于等状态，让其他线程执行。 当生产者向缓冲区放入一个产品时，向其他等待的线程发出可执行的通知，同时放弃锁，使自己处于等待状态； 当消费者从缓冲区取出一个产品时，向其他等待的线程发出可执行的通知，同时放弃锁，使自己处于等待状态。 仓库Storage.java package cn.lumingbao.demo; import java.util.LinkedList; /** * ============================ * 仓库 * @ClassName Storage * @Description * @Author lumingbao * @Date 2018/03/12 15:54 * ============================ */ public class Storage { /** * 仓库容量 */ private final int MAX_SIZE = 10; /** * 仓库存储的载体 */ private LinkedList\u003cObject\u003e list = new LinkedList\u003c\u003e(); /** * 生产 */ public void produce() { synchronized (list) { while (list.size() + 1 \u003e MAX_SIZE) { System.out.println(\"【生产者\" + Thread.currentThread().getName() + \"】仓库已满\"); try { list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } list.add(new Object()); System.out.println(\"【生产者\" + Thread.currentThread().getName() + \"】生产一个产品，现库存\" + list.size()); list.notifyAll(); } } /** * 消费 */ public void consume() { synchronized (list) { while (list.size() == 0) { System.out.println(\"【消费者\" + Thread.currentThread().getName() + \"】仓库为空\"); try { list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } list.remove(); System.out.println(\"【消费者\" + Thread.currentThread().getName() + \"】消费一个产品，现库存\" + list.size()); list.notifyAll(); } } } 生产者Producer.java package cn.lumingbao.demo; /** * ============================ * 生产者 * @ClassName Producer * @Description * @Author lumingbao * @Date 2018/03/12 15:58 * ============================ */ public class Producer implements Runnable{ private Storage storage; public Producer(){} public Producer(Storage storage){ this.storage = storage; } @Override public void run() { while(true){ try{ Thread.sleep(1000); storage.produce(); }catch (InterruptedException e){ e.printStackTrace(); } } } } 消费者Consumer.java package cn.lumingbao.demo; /** * ============================ * 消费者 * @ClassName Consumer * @Description * @Author lumingbao * @Date 2018/03/12 16:02 * ============================ */ public class Consumer implements Runnable{ private Storage storage; public Consumer(){} public Consumer(Storage storage){ this.storage = storage; } @Override public void run() { while(true){ try{ Thread.sleep(3000); storage.consume(); }catch (InterruptedException e){ e.printStackTrace(); } } } } 主函数Main.java package cn.lumingbao.demo; /** * ============================ * 主函数 * @ClassName Main * @Description * @Author lumingbao * @Date 2018/03/12 16:40 * ============================ */ public class Main { public static void main(String[] args) { Storage storage = new Storage(); Thread p1 = new Thread(new Producer(storage)); Thread p2 = new Thread(new Producer(storage)); Thread p3 = new Thread(new Producer(storage)); Thread c1 = new Thread(new Consumer(storage)); Thread c2 = new Thread(new Consumer(storage)); Thread c3 = new Thread(new Consumer(storage)); p1.start(); p2.start(); p3.start(); c1.start(); c2.start(); c3.start(); } } 运行结果： 一个生产者线程运行produce方法，睡眠1s；一个消费者运行一次consume方法，睡眠3s。此次实验过程中，有3个生产者和3个消费者，也就是我们说的多对多的情况。仓库的容量为10，可以看出消费的速度明显慢于生产的速度，符合设定。 注意： notifyAll()方法可使所有正在等待队列中等待同一共享资源的“全部”线程从等待状态退出，进入可运行状态。此时，优先级最高的哪个线程最先执行，但也有可能是随机执行的，这要取决于JVM虚拟机的实现。即最终也只有一个线程能被运行，上述线程优先级都相同，每次运行的线程都不确定是哪个，后来给线程设置优先级后也跟预期不一样，还是要看JVM的具体实现吧。 2、await() / signal()方法的实现 在JDK5中，用ReentrantLock和Condition可以实现等待/通知模型，具有更大的灵活性。通过在Lock对象上调用newCondition()方法，将条件变量和一个锁对象进行绑定，进而控制并发程序访问竞争资源的安全。 在这里只需改动Storage类 package cn.lumingbao.demo; import java.util.LinkedList; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * ============================ * 仓库 * @ClassName Storage * @Description * @Author lumingbao * @Date 2018/03/12 15:54 * ============================ */ public class Storage { /** * 仓库容量 */ private final int MAX_SIZE = 10; /** * 仓库存储的载体 */ private LinkedList\u003cObject\u003e list = new LinkedLis","date":"2018-03-12","objectID":"/archives/98162/:1:2","tags":["设计模式","JAVA"],"title":"JAVA生产者消费者模式","uri":"/archives/98162/"},{"categories":["工作记录"],"content":"Eclipse下实现maven项目在tomcat容器热部署 1.修改tomcat目录下:conf/tomcat-users.xml 文件，在节点中加入如下内容： \u003crole rolename=\"manager-gui\"/\u003e \u003crole rolename=\"manager-script\"/\u003e \u003cuser username=\"admin\" password=\"password\" roles=\"manager-gui, manager-script\"/\u003e 其中用户名和密码根据自己情况自定义。 2.修改Maven的settings.xml，在节点中加入如下代码： \u003cserver\u003e \u003cid\u003etomcat7\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003epassword\u003c/password\u003e \u003c/server\u003e 其中 id 根据自己情况自定义，username 和 password 必须和第一步中配置的用户名密码相同。 3.修改Maven项目的pom.xml文件，在节点加入如下代码： \u003cplugins\u003e \u003c!-- tomcat7的maven插件 --\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.tomcat.maven\u003c/groupId\u003e \u003cartifactId\u003etomcat7-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e2.2\u003c/version\u003e \u003cconfiguration\u003e \u003curl\u003ehttp://localhost:8080/manager/text\u003c/url\u003e \u003c!-- 此处是tomcat部署地址 --\u003e \u003cserver\u003etomcat7\u003c/server\u003e \u003c!-- 此处的名字必须和setting.xml中配置的ID一致 --\u003e \u003cpath\u003e/SpringMVC\u003c/path\u003e \u003c!-- 此处的名字是项目发布的工程名 --\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e 其中 节点对应的是第二步中的id 4.部署 右键要部署的项目选择 Run as –\u003e Run Configurations… 弹出如下界面： 如果所示： 4.1 在1处右键点击Maven Build 选择New 4.2 在2处输入自定义的Name 4.3 点击3处的按钮，选择要部署的项目 4.4 在4处输入：tomcat7:redeploy 其中 tomcat7为你之前定义的server id 4.5 点击Run运行即可 ","date":"2015-11-11","objectID":"/archives/70419/:1:0","tags":["Maven","Eclipse","Maven"],"title":"Eclipse下实现maven项目在tomcat容器热部署","uri":"/archives/70419/"},{"categories":["工作记录"],"content":"1.创建拦截器基类 /** * 抽象类 * 任何要实现拦截器都需要继承自这个类，并实现其中的interceptor方法，并添加至拦截器池中，就可以实现拦截功能 */ Ext.define('system.interceptor.BaseInterceptor',{ alternateClassName:['system.BaseInterceptor'], statics:{ BEFORE:'before', //在请求前拦截 AFTER:'after', //在请求过后拦截 AROUND:'around' //在请求前后都拦截 }, mode:'after', isInterceptor:true, //不包含的URL excludes:[], //仅包含URL，优先级大于excludes includes:[], /** * 拦截方法，执行拦截及验证过程 * @param {Object} options The options config object passed to the request method. * @param {Object} response The XHR object containing the response data. See The XMLHttpRequest Object for details. * @return {Boolean} */ interceptor:Ext.emptyFn(), constructor:function(interceptorFn){ var me = this; if(Ext.isObject(interceptorFn)){ //me.interceptor = interceptorFn; Ext.apply(me,interceptorFn); }else if(Ext.isFunction(interceptorFn)){ me.interceptor = interceptorFn; } }, getId:function(){ return this.id; }, /** * 处理拦截过程 * @param {} options */ handler:function(options,response){ if (this.validationUrl(options.url)) { return this.interceptor(options,response); } }, /** * 验证URL是否需要拦截 * @param {String} url 需要验证的地址 */ validationUrl:function(url){ var me = this, intercept = false; //如果配置了include就仅验证包含的URL //如果配置了excludes就仅不包含excludes中的URL //如果都没有配置就拦截所有URL if(me.includes.length == 0 \u0026\u0026 me.excludes.length == 0){ intercept = true; }else if(me.includes.length\u003e0){ //满足条件说明需要拦截 Ext.Array.each(this.includes,function(reg){ //url.match(reg) var reg = new RegExp(reg); if(reg.test(url))intercept = true; return false; }); }else{ intercept = true; Ext.Array.each(this.excludes,function(reg){ var reg = new RegExp(reg); if(reg.test(url))intercept = false; return false; }); } return intercept; } }); ","date":"2015-10-30","objectID":"/archives/14181/:0:1","tags":["Extjs"],"title":"Extjs 添加拦截器，对后台异常做统一的前台处理","uri":"/archives/14181/"},{"categories":["工作记录"],"content":"2.创建异常拦截器。继承前面创建的拦截器基类 /** * 异常拦截器 * 处理后台返回的有异常信息的请求(包括代码异常，业务异常，session超时) */ Ext.define('system.interceptor.ExceptionInterceptor',{ extend:'system.interceptor.BaseInterceptor', interceptor:function(options,response){ var resultData = Ext.decode(response.responseText); /** * 处理代码异常和业务异常 */ if(resultData.isException){ Ext.MessageBox.alert(resultData.exName,resultData.message); return false; } /** * 处理Session超时 */ if(resultData.isSessionOut){ Ext.MessageBox.alert('Session超时','Session超时，请重新登录！',function(){ window.location = Ext.CONTEXT+'login'; }); return false; } return true; } }); ","date":"2015-10-30","objectID":"/archives/14181/:0:2","tags":["Extjs"],"title":"Extjs 添加拦截器，对后台异常做统一的前台处理","uri":"/archives/14181/"},{"categories":["工作记录"],"content":"3.重写Ext.Ajax /** * 重写Ext.Ajax的意思在于：添加拦截器，对后台异常、session超时信息在前台进行统一的处理。 */ Ext.define('Ext.Ajax',{ extend: 'Ext.data.Connection', singleton: true, autoAbort: false, //是否允许在请求前拦截 enableBeforeInterceptor:false, interceptors:Ext.create('Ext.util.MixedCollection'), //执行拦截操作 invokeInterceptor:function(options,response,mode){ var me = this; this.interceptors.each(function(interceptor){ //判断拦截器类型 if(interceptor.mode == mode || interceptor.mode == Xzr.AbstractInterceptor.AROUND ){ //执行拦截操作，如果没有通过拦截器则返回false if(interceptor.handler(options,response) === false){ return false; }; } }); return true; }, //通过listener实现对Ajax访问的拦截 listeners :{ //拦截器处理，如果没有通过拦截器，则取消请求 beforerequest:function( conn, options, eOpts ){ if(this.enableBeforeInterceptor){ return this.invokeInterceptor(options,null,'before'); } return true; }, //请求完成后对数据验证，无法中断后续的操作，具体请研究ExtJs源码。 requestcomplete:function(conn, response, options, eOpts){ return this.invokeInterceptor(options,response,'after'); } }, /** * 添加拦截器 * @param {String} interceptorId * @param {Xzr.web.AbstractInterceptor} interceptor */ addInterceptor:function(interceptor){ if(!interceptor)return; if(Ext.isString(interceptor)){ interceptor = Ext.create(interceptor); } this.interceptors.add(interceptor.getId(),interceptor); } }); ","date":"2015-10-30","objectID":"/archives/14181/:0:3","tags":["Extjs"],"title":"Extjs 添加拦截器，对后台异常做统一的前台处理","uri":"/archives/14181/"},{"categories":["工作记录"],"content":"4.将异常拦截器添加到拦截池中 Ext.onReady(function() { Ext.Ajax.addInterceptor('system.interceptor.ExceptionInterceptor'); }); ","date":"2015-10-30","objectID":"/archives/14181/:0:4","tags":["Extjs"],"title":"Extjs 添加拦截器，对后台异常做统一的前台处理","uri":"/archives/14181/"},{"categories":["工作记录"],"content":"5.后台统一捕获代码异常和业务异常 package com.fsd.controller; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.apache.log4j.Logger; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.ResponseBody; import com.fsd.bean.ExceptionInfo; import com.fsd.common.BusinessException; public class BaseController { private static final Logger log = Logger.getLogger(BaseController.class); /** 基于@ExceptionHandler异常处理 */ @ExceptionHandler public @ResponseBody Object resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { ExceptionInfo exinfo = new ExceptionInfo(); if(ex instanceof BusinessException) { exinfo.setIsException(true); exinfo.setExTtype(\"bizexception\"); exinfo.setExName(\"业务异常\"); exinfo.setExDetails(ex.toString()); exinfo.setMessage(ex.getMessage()); }else { exinfo.setIsException(true); exinfo.setExTtype(\"exception\"); exinfo.setExName(\"代码异常\"); exinfo.setExDetails(ex.toString()); exinfo.setMessage(ex.getMessage()); ex.printStackTrace(); } log.error(ex); return exinfo; } } ","date":"2015-10-30","objectID":"/archives/14181/:0:5","tags":["Extjs"],"title":"Extjs 添加拦截器，对后台异常做统一的前台处理","uri":"/archives/14181/"},{"categories":["工作记录"],"content":"Maven私服 - Nexus仓库教程 ","date":"2015-10-24","objectID":"/archives/25058/:1:0","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"一、Nexus介绍 Nexus 是Maven仓库管理器，如果你使用Maven，你可以从Maven中央仓库 下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。 ","date":"2015-10-24","objectID":"/archives/25058/:2:0","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"二、环境搭建 ","date":"2015-10-24","objectID":"/archives/25058/:3:0","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"2.1 下载 http://www.sonatype.org/nexus/ NEXUS OSS [OSS = Open Source Software，开源软件——免费] NEXUS PROFESSIONAL -FREE TRIAL [专业版本——收费]。 所以选择NEXUS OSS 找到Download andInstall Nexus OSS。下载ZIP的即可： ","date":"2015-10-24","objectID":"/archives/25058/:3:1","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"2.2 配置 解压下载好的压缩包，等到如下目录结构： 配置环境变量： 新建 NEXUS_HOME环境变量值为你解压的nexus根目录，如下图所示： 再配置Path环境变量末尾加入 %NEXUS_HOME%\\bin\\jsw\\windows-x86-64 最后的 windows-x86-64 部分取决有你的操作系统类型，如下图所示： ","date":"2015-10-24","objectID":"/archives/25058/:3:2","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"2.3 启动 执行CMD命令进入命令提示符模式： 安装命令：install-nexus.bat 启动命令：start-nexus.bat 如果所示： 启动成功以后本机访问：http://127.0.0.1:8081/nexus 出现如下界面，说明配置成功！ ","date":"2015-10-24","objectID":"/archives/25058/:3:3","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"三、使用教程 ","date":"2015-10-24","objectID":"/archives/25058/:4:0","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"3.1 代理外部Maven仓库 3.1.1 登陆 要管理Nexus，你首先需要以管理员身份登陆，点击界面右上角的login，输入默认的登录名和密码：admin/admin123，登陆成功后，你会看到左边的导航栏增加了很多内容： 这里，可以管理仓库，配置Nexus系统，管理任务，管理用户，角色，权限，查看系统的RSS源，管理及查看系统日志，等等。你会看到Nexus的功能十分丰富和强大，本文，笔者只介绍一些最基本的管理和操作。 3.1.2 代理Maven中央仓库 点击左边导航栏的Repositories，界面的主面板会显示所有一个所有仓库及仓库组的列表，你会看到它们的Type字段的值有group，hosted，proxy，virtual。这里我们不关心virtual，只介绍下另外三种类型： hosted，本地仓库，通常我们会部署自己的构件到这一类型的仓库。 proxy，代理仓库，它们被用来代理远程的公共仓库，如maven中央仓库。 group，仓库组，用来合并多个hosted/proxy仓库，通常我们配置maven依赖仓库组。 由此我们知道，我们需要配置一个Maven中央仓库的proxy，其实Nexus已经内置了Maven Central，但我们需要做一些配置。点击仓库列表中的Maven Central，你会注意到它的Policy是release，这说明它不会代理远程仓库的snapshot构件，这是有原因的，远程仓库的snapshot版本构件不稳定且不受你控制，使用这样的构件含有潜在的风险。然后我们发现主面板下方有三个Tab，分别为Browse，Configuration和Mirrors，我们点击Configuration进行配置，你现在需要关心的是两个配置项：“Remote Storage Location”为远程仓库的地址，对于Maven Central来说是http://repo1.maven.org/maven2/；“Download Remote Indexes”顾名思义是指是否下载远程索引文件，Maven Central的该字段默认为False，这是为了防止大量Nexus无意识的去消耗中央仓库的带宽（中央仓库有大量的构件，其索引文件也很大）。这里我们需要将其设置为True，然后点击Save。在Nexus下载的中央仓库索引文件之后，我们就可以在本地搜索中央仓库的所有构件。下图展示了我们刚才所涉及的配置： 3.1.3 添加一个代理仓库 这里我们再举一个例子，我们想要代理Sonatype的公共仓库，其地址为：http://repository.sonatype.org/content/groups/public/。步骤如下，在Repositories面板的上方，点击Add，然后选择Proxy Repository，在下方的配置部分，我们填写如下的信息：Repository ID - sonatype；Repository Name - Sonatype Repository；Remote Storage Location - http://repository.sonatype.org/content/groups/public/。其余的保持默认值，需要注意的是Repository Policy，我们不想代理snapshot构件，原因前面已经描述。然后点击Save。配置页面如下： ","date":"2015-10-24","objectID":"/archives/25058/:4:1","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"3.2 代理外部Maven仓库 Nexus预定义了3个本地仓库，分别为Releases，Snapshots，和3rd Party。这三个仓库都有各自明确的目的。Releases用于部署我们自己的release构件，Snapshots用于部署我们自己的snapshot构件，而3rd Party用于部署第三方构件，有些构件如Oracle的JDBC驱动，我们不能从公共仓库下载到，我们就需要将其部署到自己的仓库中。 当然你也可以创建自己的本地仓库，步骤和创建代理仓库类似，点击Repository面板上方的Add按钮，然后选择Hosted Repository，然后在下方的配置面板中输入id和name，注意这里我们不再需要填写远程仓库地址，Repository Type则为不可修改的hosted，而关于Repository Policy，你可以根据自己的需要选择Release或者Snapshot，如图： ","date":"2015-10-24","objectID":"/archives/25058/:4:2","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"3.3 代理外部Maven仓库 Nexus中仓库组的概念是Maven没有的，在Maven看来，不管你是hosted也好，proxy也好，或者group也好，对我都是一样的，我只管根据groupId，artifactId，version等信息向你要构件。为了方便Maven的配置，Nexus能够将多个仓库，hosted或者proxy合并成一个group，这样，Maven只需要依赖于一个group，便能使用所有该group包含的仓库的内容。 Nexus预定义了“Public Repositories”和“Public Snapshot Repositories”两个仓库组，前者默认合并所有预定义的Release仓库，后者默认合并所有预定义的Snapshot仓库。我们在本文前面的部分创建了一个名为“Sonatype Repository”的仓库，现在将其合并到“Public Repositories”中。 点击仓库列表中的“Public Repositories”，然后选择下方的\"Configuration\" Tab，在配置面板中，将右边“Avaiable Repositories”中的“Sonatype Repository”拖拽到左边的“Ordered Group Repository”中，如图： 创建仓库组和创建proxy及hosted仓库类似，这里不再赘述。需要注意的是format字段需要填写“maven2”，添加你感兴趣的仓库即可。 ","date":"2015-10-24","objectID":"/archives/25058/:4:3","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":["工作记录"],"content":"四、总结 本文介绍强大的仓库管理器——Nexus，包括如何下载安装Nexus，配置Nexus代理中央仓库，管理Nexus的代理仓库，本地仓库，以及仓库组。并帮助你了解如何通过Nexus搜索构件。最后，如何在Maven中配置Nexus仓库，以及如何部署构件到Nexus仓库中。这些都是Nexus中最基本也是最常用的功能。随着使用的深入，你会发现Nexus还有很多其它的特性，如用户管理，角色权限管理等等。 Nexus的OSS版本是完全开源的，如果你有兴趣，你可以学习其源码，甚至自己实现一个REST客户端。 马上拥抱Nexus吧，它是免费的！ ","date":"2015-10-24","objectID":"/archives/25058/:5:0","tags":["Maven"],"title":"Maven私服-Nexus仓库搭建教程","uri":"/archives/25058/"},{"categories":null,"content":"Hi ! ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"My name is lumingbao. I’m a Java Developer with an enduring interest in Coding and Write Blog. ","date":"0001-01-01","objectID":"/about/:0:1","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"About Hi! 你好，我是芦明宝, 专注Java开发， 喜欢代码艺术， 关注新技术 喜欢运动， 音乐 ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Work 摸鱼爱好者 ","date":"0001-01-01","objectID":"/about/:2:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"Concat ","date":"0001-01-01","objectID":"/about/:3:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":" 吴汶泽 一名优秀的软件工程师 ","date":"0001-01-01","objectID":"/friend/:0:0","tags":null,"title":"友情链接","uri":"/friend/"}]